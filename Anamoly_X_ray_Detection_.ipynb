{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RISHIshrivas/Anamoly-X-ray-Detection-/blob/main/Anamoly_X_ray_Detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO5A-k7biCZL",
        "outputId": "ecfa342e-427e-4d8c-ad85-26e565cc2c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "os.environ['KAGGLE_USERNAME'] = \"chadrishi\"\n",
        "os.environ['KAGGLE_KEY'] = \"2ae8d27b85a0ffe192c8b84b729c663e\"\n",
        "!kaggle datasets download vuppalaadithyasairam/bone-fracture-detection-using-xrays\n",
        "!unzip bone-fracture-detection-using-xrays.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luvZ0sfMiFYo",
        "outputId": "4d0b21f2-838f-4e2d-b771-64a06b8583bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of images in normal xrays of training set:  2552\n",
            "No. of images in fractured xrays of training set:  4383\n",
            "No. of images in normal xrays of test set:  240\n",
            "No. of images in fractured xrays of test set:  360\n"
          ]
        }
      ],
      "source": [
        "print(\"No. of images in normal xrays of training set: \",len(os.listdir('archive (6)/train/fractured')))\n",
        "print(\"No. of images in fractured xrays of training set: \",len(os.listdir('archive (6)/train/not fractured')))\n",
        "print(\"No. of images in normal xrays of test set: \",len(os.listdir('archive (6)/val/not fractured')))\n",
        "print(\"No. of images in fractured xrays of test set: \",len(os.listdir('archive (6)/val/fractured')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yShcytPZiUdZ"
      },
      "outputs": [],
      "source": [
        "def delete_extra_images(f_path,num_images) :\n",
        "    files = os.listdir(f_path)\n",
        "    num_images = min(num_images,len(files))\n",
        "    for i in range(num_images):\n",
        "      file = os.path.join(f_path,files[i])\n",
        "      os.remove(file)\n",
        "      print(f\"Deleted: {file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKbPT8bAiVcO",
        "outputId": "3582b9bf-6ffd-411d-f711-2d629ef3b571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted: archive (6)/train/fractured\\36-rotated1-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated1-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated1-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\36.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\37.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated1-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated1-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated1-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated2-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated2-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated3-rotated1.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated3-rotated2.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated3-rotated3.jpg\n",
            "Deleted: archive (6)/train/fractured\\38-rotated2-rotated3.jpg\n"
          ]
        }
      ],
      "source": [
        "delete_extra_images(f_path='archive (6)/train/fractured',num_images=97)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP3I2b87iZmR",
        "outputId": "f990b0eb-a9ae-46fa-e7b5-4596d7a95dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of images in normal xrays of training set:  2455\n",
            "No. of images in fractured xrays of training set:  4383\n"
          ]
        }
      ],
      "source": [
        "print(\"No. of images in normal xrays of training set: \",len(os.listdir('archive (6)/train/fractured')))\n",
        "print(\"No. of images in fractured xrays of training set: \",len(os.listdir('archive (6)/train/not fractured')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi95mbiFie0h"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def display_images(f_path,max_num_images):\n",
        "  if not os.path.exists(f_path):\n",
        "    print(f\"{f_path} does not exist\")\n",
        "    return\n",
        "  for f in os.listdir(f_path):\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg', )):\n",
        "      images = []\n",
        "      images.append(f)\n",
        "    count = 0\n",
        "    for image in images:\n",
        "      if count>=max_num_images:\n",
        "        break\n",
        "      image_path = os.path.join(f_path,image)\n",
        "      img = Image.open(image_path)\n",
        "      plt.imshow(img)\n",
        "      plt.title(image)\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "      count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQI1AhyNiiWT"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "train_fractured_path = 'archive (6)/train/fractured'\n",
        "train_not_fractured_path = 'archive (6)/train/not fractured'\n",
        "val_fractured_path = 'archive (6)/val/fractured'\n",
        "val_not_fractured_path = 'archive (6)/val/not fractured'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luEYYjdNimeR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "def preprocess_images(folder_path, label, target_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, file)\n",
        "        img = Image.open(image_path)\n",
        "        img = img.resize(target_size)\n",
        "        img = np.array(img)\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.stack((img,) * 3, axis=-1)\n",
        "        img = img / 255.0\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KunN33Lv0840",
        "outputId": "5061f3df-2b61-46e9-aeb0-a451e5c3a7ee"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 2.75 GiB for an array with shape (2455, 224, 224, 3) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_fractured_images, train_fractured_labels \u001b[39m=\u001b[39m preprocess_images(train_fractured_path, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_not_fractured_images, train_not_fractured_labels \u001b[39m=\u001b[39m preprocess_images(train_not_fractured_path, \u001b[39m0\u001b[39m)\n",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     labels\u001b[39m.\u001b[39mappend(label)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(images), np\u001b[39m.\u001b[39marray(labels)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.75 GiB for an array with shape (2455, 224, 224, 3) and data type float64"
          ]
        }
      ],
      "source": [
        "train_fractured_images, train_fractured_labels = preprocess_images(train_fractured_path, 1)\n",
        "train_not_fractured_images, train_not_fractured_labels = preprocess_images(train_not_fractured_path, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lyt7hwIAjK_y"
      },
      "outputs": [],
      "source": [
        "val_fractured_images, val_fractured_labels = preprocess_images(val_fractured_path, 1)\n",
        "val_not_fractured_images, val_not_fractured_labels = preprocess_images(val_not_fractured_path, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVxnZUXjjkFM"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "val_images = np.concatenate((val_fractured_images, val_not_fractured_images), axis=0)\n",
        "val_labels = np.concatenate((val_fractured_labels, val_not_fractured_labels), axis=0)\n",
        "val_labels = to_categorical(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4knuZlvQizyZ",
        "outputId": "54f3f3b3-64e7-4d70-f026-dd5ad736d8c3"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 7.78 GiB for an array with shape (6935, 224, 224, 3) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate((train_fractured_images, train_not_fractured_images), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((train_fractured_labels, train_not_fractured_labels), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_labels \u001b[39m=\u001b[39m to_categorical(train_labels)\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.78 GiB for an array with shape (6935, 224, 224, 3) and data type float64"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_images = np.concatenate((train_fractured_images, train_not_fractured_images), axis=0)\n",
        "train_labels = np.concatenate((train_fractured_labels, train_not_fractured_labels), axis=0)\n",
        "train_labels = to_categorical(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g5ABPK_jp_U",
        "outputId": "cdf1d873-99ca-4550-a988-960a778ab763"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 7.77 GiB for an array with shape (6932, 224, 224, 3) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train,X_test,y_train,y_test \u001b[39m=\u001b[39m train_test_split(train_images, train_labels, test_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2640\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> 2640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2642\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m   2640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:355\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    354\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:184\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    183\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m array[key] \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m array[:, key]\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.77 GiB for an array with shape (6932, 224, 224, 3) and data type float64"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(train_images, train_labels, test_size=3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxSUbB1Pj4Y-",
        "outputId": "82909f6b-3fe2-45c1-8f29-a8dbd18effd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 56, 56, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 27, 27, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 27, 27, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 490274 (1.87 MB)\n",
            "Trainable params: 490274 (1.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Flatten the output before feeding into Dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQpkxdth1kH0",
        "outputId": "0add4562-da8c-4e98-dca8-baaad4ed773a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 111, 111, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 55, 55, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 55, 55, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 27, 27, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 27, 27, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 43264)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               5537920   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5934722 (22.64 MB)\n",
            "Trainable params: 5934722 (22.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)  # Adjust learning rate as needed\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJxk5BXjXIA8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pahSKfxHktSU"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvD5DRanZ3fp",
        "outputId": "09de70f7-917b-49ef-f924-6f55bd73e3d0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m r \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "#Train the model\n",
        "r = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVlZIIjKmuZk",
        "outputId": "69a62948-2a30-4232-eda9-9bc490180f42"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\HP\\Downloads\\DL_PROJECT_FINAL (1).ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/DL_PROJECT_FINAL%20%281%29.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_test, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=0)\n",
        "y_test = np.reshape(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbfLyIrHnIl-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "df_cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKDhrYLCnmak"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "model_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"model accuracy: \", model_accuracy*100)\n",
        "precison = precision_score(y_test, y_pred)\n",
        "print(\"model precision: \", precison*100)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"model recall: \", recall*100)\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "print(\"model f1_score: \", f1*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvgHHSF9WW56"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 16))\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='val_Loss')\n",
        "plt.title('Loss Function Evolution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Accuracy Function Evolution')\n",
        "plt.legend()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxpJYalkWr87"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqCK7PRrWso9"
      },
      "outputs": [],
      "source": [
        "plt.plot(r.history['accuracy'], label='acc', color='red')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc', color='green')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}